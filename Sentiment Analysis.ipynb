{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sentiment Analysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "\n",
    "# Read dialogue data from s3\n",
    "dataframe = spark \\\n",
    "    .read \\\n",
    "    .load(\"s3://strata-demo-data/nlp_data/Dialogue-dataset/trainline_dialogue.csv\",\n",
    "          format=\"csv\", inferSchema=\"true\", header=\"true\")\n",
    "          \n",
    "change_speaker_name_udf = F.udf(lambda speaker: 'Call Agent' if speaker == 'A' else 'Customer', StringType())\n",
    "dataframe = dataframe.withColumn('speaker', change_speaker_name_udf(dataframe.speaker))\n",
    "          \n",
    "dataframe.show(5)\n",
    "\n",
    "# Only keep rows with sentiment data for modelling\n",
    "filtered_dataframe = dataframe.na.drop(subset=['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "first_ten_examples = dataframe.select(F.col('speaker'), F.col('response'), F.col('polarity')).take(10)\n",
    "print('First 10 responses:')\n",
    "for example in first_ten_examples:\n",
    "    print '{} - \"{} ({})\"'.format(example.speaker, example.response, example.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Sentiment within Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "grouped_dataframe = dataframe.groupBy('polarity').count()\n",
    "sentiments = grouped_dataframe.select('polarity').collect()\n",
    "sentiments = ['null' if sentiment.polarity is None else sentiment.polarity for sentiment in sentiments]\n",
    "counts = grouped_dataframe.select('count').collect()\n",
    "counts = [c['count'] for c in counts]\n",
    "\n",
    "grouped_dataframe_speaker = dataframe.groupBy(['speaker', 'polarity']).count().orderBy('speaker', desc('count'))\n",
    "speaker_a_counts = grouped_dataframe_speaker.filter(grouped_dataframe_speaker.speaker == 'Call Agent').select('count').collect()\n",
    "speaker_a_counts = [c['count'] for c in speaker_a_counts]\n",
    "speaker_b_counts = grouped_dataframe_speaker.filter(grouped_dataframe_speaker.speaker == 'Customer').select('count').collect()\n",
    "speaker_b_counts = [c['count'] for c in speaker_b_counts]\n",
    "\n",
    "fig, axarr = plt.subplots(2, sharex=True)\n",
    "fig.suptitle('Breakdown of Sentiment within Dialogues', fontsize=15)\n",
    "\n",
    "axarr[0].bar(x=sentiments, height=counts)\n",
    "axarr[0].set_title('(All Responses)')\n",
    "axarr[0].set_ylabel('Total Responses', fontsize=13)\n",
    "\n",
    "p1 = axarr[1].bar(x=sentiments, height=speaker_a_counts)\n",
    "p2 = axarr[1].bar(x=sentiments, height=speaker_b_counts, bottom=speaker_a_counts)\n",
    "\n",
    "axarr[1].set_title('(Responses Split by Speaker)')\n",
    "axarr[1].set_xlabel('Sentiment', fontsize=13)\n",
    "axarr[1].set_ylabel('Total Responses', fontsize=13)\n",
    "axarr[1].legend((p1[0], p2[0]), ('Call Agent', 'Customer'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\r\n",
    "five_positive_examples_a = dataframe.select(F.col('speaker'), F.col('response'), F.col('polarity')).filter((dataframe.polarity == 'positive') & (dataframe.speaker == 'Call Agent')).take(5)\r\n",
    "five_positive_examples_b = dataframe.select(F.col('speaker'), F.col('response'), F.col('polarity')).filter((dataframe.polarity == 'positive') & (dataframe.speaker == 'Customer')).take(5)\r\n",
    "five_negative_examples_a = dataframe.select(F.col('speaker'), F.col('response'), F.col('polarity')).filter((dataframe.polarity == 'negative') & (dataframe.speaker == 'Call Agent')).take(5)\r\n",
    "five_negative_examples_b = dataframe.select(F.col('speaker'), F.col('response'), F.col('polarity')).filter((dataframe.polarity == 'negative') & (dataframe.speaker == 'Customer')).take(5)\r\n",
    "\r\n",
    "print('Positive examples (Call Agent):')\r\n",
    "for example in five_positive_examples_a:\r\n",
    "    print '{} - \"{} ({})\"'.format(example.speaker, example.response, example.polarity)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "print('Negative examples (Call Agent):')\n",
    "for example in five_negative_examples_a:\n",
    "    print '{} - \"{} ({})\"'.format(example.speaker, example.response, example.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "print('Positive examples (Customer):')\n",
    "for example in five_positive_examples_b:\n",
    "    print '{} - \"{} ({})\"'.format(example.speaker, example.response, example.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "print('Negative examples (Customer):')\n",
    "for example in five_negative_examples_b:\n",
    "    print '{} - \"{} ({})\"'.format(example.speaker, example.response, example.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Topic Distributions for Negative Responses"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "top_five_negative_topics = dataframe \\\n",
    "    .filter(dataframe.polarity == 'negative') \\\n",
    "    .groupBy('topic') \\\n",
    "    .count() \\\n",
    "    .orderBy(desc('count')) \\\n",
    "    .limit(5)\n",
    "\n",
    "topics = top_five_negative_topics.select('topic').collect()\n",
    "topics = ['null' if t.topic is None else t.topic for t in topics]\n",
    "topic_counts = top_five_negative_topics.select('count').collect()\n",
    "topic_counts = [c['count'] for c in topic_counts]\n",
    "\n",
    "plt.bar(x=topics, height=topic_counts)\n",
    "plt.title('Top 5 \\'Negative\\' Topics within Dialogues', fontsize=15)\n",
    "plt.xlabel('Topics', fontsize=13)\n",
    "plt.ylabel('Total Negative Responses', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "import string\n",
    "\n",
    "remove_punctuation_udf = F.udf(lambda response: response.replace('.', '').replace(',', '').replace('!', '').replace('?', ''), StringType())\n",
    "create_labels_udf = F.udf(lambda polarity: 1 if polarity == 'positive' else 0, IntegerType())\n",
    "\n",
    "cleaned_dataframe = filtered_dataframe \\\n",
    "    .withColumn('cleaned response', remove_punctuation_udf(filtered_dataframe.response)) \\\n",
    "    .withColumn('label', create_labels_udf(filtered_dataframe.polarity)) \\\n",
    "    .select(F.col('id'), F.col('conversation id'), F.col('turn number'), F.col('speaker'),  F.col('response'), F.col('cleaned response'), F.col('topic'), F.col('polarity'), F.col('label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Word Distributions for Positive and Negative Responses"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "all_positive_responses = cleaned_dataframe.filter(dataframe.polarity == 'positive')\n",
    "all_negative_responses = cleaned_dataframe.filter(dataframe.polarity == 'negative')\n",
    "\n",
    "# Tokenize responses\n",
    "tokenizer = Tokenizer().setInputCol('cleaned response').setOutputCol('words')\n",
    "\n",
    "# Get stopwords\n",
    "#stop_words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words') \\\n",
    "#    .text.split()\n",
    "stop_words = requests.get('https://raw.githubusercontent.com/igorbrigadir/stopwords/master/en/bow_short.txt') \\\n",
    "    .text.split()\n",
    "additional_stopwords = ['uh', 'um', 'uh-huh', 'um-hum', 'em', 'ah', 'er', 'erm']\n",
    "additional_stopwords.extend([str(i) for i in range(100)])\n",
    "stop_words.extend(additional_stopwords)\n",
    "\n",
    "# Prepare stopwords remover\n",
    "sw_filter = StopWordsRemover() \\\n",
    "    .setStopWords(stop_words) \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setInputCol('words') \\\n",
    "    .setOutputCol('filtered')\n",
    "\n",
    "positive_tokenization_pipeline = Pipeline(stages=[tokenizer, sw_filter]).fit(all_positive_responses)\n",
    "negative_tokenization_pipeline = Pipeline(stages=[tokenizer, sw_filter]).fit(all_negative_responses)\n",
    "tokenized_positive_responses = positive_tokenization_pipeline.transform(all_positive_responses)\n",
    "tokenized_negative_responses = negative_tokenization_pipeline.transform(all_negative_responses)\n",
    "\n",
    "positive_words = tokenized_positive_responses.select('filtered').collect()\n",
    "positive_words = list(itertools.chain.from_iterable([word.filtered for word in positive_words]))\n",
    "positive_words_distinct = list(set(positive_words))\n",
    "positive_words_cleaned = [word for word in positive_words_distinct if word != '']\n",
    "positive_word_counts = [positive_words.count(word) for word in positive_words_cleaned]\n",
    "positive_wordcount_df = pd.DataFrame({'word': positive_words_cleaned, 'count': positive_word_counts}).sort_values(by=['count'], ascending=False).head(10)\n",
    "\n",
    "negative_words = tokenized_negative_responses.select('filtered').collect()\n",
    "negative_words = list(itertools.chain.from_iterable([word.filtered for word in negative_words]))\n",
    "negative_words_distinct = list(set(negative_words))\n",
    "negative_words_cleaned = [word for word in negative_words_distinct if word != '']\n",
    "negative_word_counts = [negative_words.count(word) for word in negative_words_cleaned]\n",
    "negative_wordcount_df = pd.DataFrame({'word': negative_words_cleaned, 'count': negative_word_counts}).sort_values(by=['count'], ascending=False).head(10)\n",
    "\n",
    "fig, axarr = plt.subplots(2, sharex=False)\n",
    "fig.suptitle('Word Distributions for Positive and Negative Responses')\n",
    "\n",
    "axarr[0].bar(x=positive_wordcount_df.word, height=positive_wordcount_df['count'], color='green')\n",
    "axarr[0].set_ylabel('Positive Word Count', fontsize=13)\n",
    "axarr[0].legend(['Positive'])\n",
    "\n",
    "axarr[1].bar(x=negative_wordcount_df.word, height=negative_wordcount_df['count'], color='red')\n",
    "axarr[1].set_ylabel('Negative Word Count', fontsize=13)\n",
    "axarr[1].set_xlabel('Word', fontsize=13)\n",
    "axarr[1].legend(['Negative'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## Spark ML Pipeline\n",
    "![image](https://s3.eu-west-2.amazonaws.com/strata-demo-data/nlp_data/Dialogue-dataset/Pipeline.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "cleaned_dataframe.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "import requests\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "\n",
    "\n",
    "# Prepare count vectorizer and remove words that appear in less than 5 'docs'\n",
    "cv = CountVectorizer(minTF=1., minDF=5) \\\n",
    "    .setInputCol('filtered') \\\n",
    "    .setOutputCol('tf')\n",
    "\n",
    "# Create count vectorizer pipeline\n",
    "cv_pipeline = Pipeline(stages=[tokenizer, sw_filter, cv]).fit(cleaned_dataframe)\n",
    "\n",
    "# Create IDF pipeline\n",
    "idf = IDF() \\\n",
    "    .setInputCol('tf') \\\n",
    "    .setOutputCol('tfidf')\n",
    "\n",
    "idf_pipeline = Pipeline(stages=[cv_pipeline, idf]).fit(cleaned_dataframe)\n",
    "idf_pipeline.transform(cleaned_dataframe).show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "import pyspark.sql.functions as fn\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "training_df, testing_df = cleaned_dataframe.randomSplit([0.7, 0.3], seed=0)\n",
    "print 'Total Rows in Training Set: {}'.format(training_df.count())\n",
    "print 'Total Rows in Test Set: {}'.format(testing_df.count())\n",
    "\n",
    "lr = LogisticRegression() \\\n",
    "    .setLabelCol('label') \\\n",
    "    .setFeaturesCol('tfidf') \\\n",
    "    .setRegParam(0.0) \\\n",
    "    .setMaxIter(100) \\\n",
    "    .setElasticNetParam(0.)\n",
    "\n",
    "# Create logistic regression pipeline\n",
    "print 'Fitting Logistic Regression model on training data set...'\n",
    "lr_pipeline = Pipeline(stages=[idf_pipeline, lr]).fit(training_df)\n",
    "\n",
    "print 'Transforming validation data set...'\n",
    "print 'Calculating accuracy...'\n",
    "lr_accuracy = lr_pipeline.transform(testing_df) \\\n",
    "    .select(fn.expr('float(prediction = label)').alias('correct')) \\\n",
    "    .select(fn.avg('correct')).collect()\n",
    "print lr_accuracy[0]['avg(correct)']"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "import pandas as pd\n",
    "\n",
    "vocabulary = idf_pipeline.stages[0].stages[-1].vocabulary\n",
    "weights = lr_pipeline.stages[-1].coefficients.toArray()\n",
    "coeffs_df = pd.DataFrame({'word': vocabulary, 'coefficient': weights})\n",
    "\n",
    "print 'Generating Top 15 Negative Words'\n",
    "# Top 15 'Negative' words based on weights of trained model\n",
    "negative_coeffs_df = coeffs_df.sort_values('coefficient').head(15)\n",
    "negative_coeffs_spark_df = spark.createDataFrame(negative_coeffs_df)\n",
    "negative_coeffs_spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "\n",
    "print 'Generating Top 15 Positive Words'\n",
    "# Top 15 'Positive' words based on weights of trained model\n",
    "positive_coeffs_df = coeffs_df.sort_values('coefficient', ascending=False).head(15)\n",
    "positive_coeffs_spark_df = spark.createDataFrame(positive_coeffs_df)\n",
    "positive_coeffs_spark_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning - Regularisation and Param Grid\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "import numpy as np\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "lambda_par = 0.02\n",
    "alpha_par = 0.3\n",
    "\n",
    "en_lr = LogisticRegression() \\\n",
    "    .setLabelCol('label') \\\n",
    "    .setFeaturesCol('tfidf') \\\n",
    "    .setRegParam(lambda_par) \\\n",
    "    .setMaxIter(100) \\\n",
    "    .setElasticNetParam(alpha_par)\n",
    "    \n",
    "en_lr_estimator = Pipeline(stages=[idf_pipeline, en_lr])\n",
    "\n",
    "grid = ParamGridBuilder() \\\n",
    "    .addGrid(en_lr.regParam, [0., 0.01, 0.02, 0.03, 0.04, 0.05]) \\\n",
    "    .addGrid(en_lr.elasticNetParam, [0., 0.2, 0.4, 0.6, 0.8, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "all_models = []\n",
    "\n",
    "param_grid_length = len(grid)\n",
    "for j in range(param_grid_length):\n",
    "    print 'Fitting model {} of {}'.format((j + 1), param_grid_length)\n",
    "    model = en_lr_estimator.fit(training_df, grid[j])\n",
    "    all_models.append(model)\n",
    "\n",
    "accuracies = [m \\\n",
    "    .transform(testing_df) \\\n",
    "    .select(fn.avg(fn.expr('float(prediction = label)')).alias('accuracy')) \\\n",
    "    .first() \\\n",
    "    .accuracy for m in all_models]\n",
    "\n",
    "best_model_idx = np.argmax(accuracies)\n",
    "\n",
    "print 'Determining best model...'\n",
    "best_model = all_models[best_model_idx]\n",
    "\n",
    "print 'Calculating accuracy for best model...'\n",
    "print accuracies[best_model_idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "# Get Top 15 negative and positive words based on weights for best model\n",
    "en_lr_best_pipeline = en_lr_estimator.fit(training_df, grid[best_model_idx])\n",
    "en_weights = en_lr_best_pipeline.stages[-1].coefficients.toArray()\n",
    "en_coeffs_df = pd.DataFrame({'word': vocabulary, 'coefficient': en_weights})\n",
    "\n",
    "print 'Top 15 Negative Words from Best Model'\n",
    "# Top 15 'Negative' words based on weights of trained model\n",
    "negative_en_coeffs_df = en_coeffs_df.sort_values('coefficient').head(15)\n",
    "negative_en_coeffs_spark_df = spark.createDataFrame(negative_en_coeffs_df)\n",
    "negative_en_coeffs_spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "print 'Top 15 Positive Words from Best Model'\n",
    "# Top 15 'Positive' words based on weights of trained model\n",
    "positive_en_coeffs_df = en_coeffs_df.sort_values('coefficient', ascending=False).head(15)\n",
    "positive_en_coeffs_spark_df = spark.createDataFrame(positive_en_coeffs_df)\n",
    "positive_en_coeffs_spark_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Responses with Missing Sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n",
    "import random\n",
    "\n",
    "missing_sentiment_dataframe = dataframe \\\n",
    "    .filter(dataframe.polarity.isNull())\n",
    "    \n",
    "cleaned_missing_sentiment_dataframe = missing_sentiment_dataframe \\\n",
    "    .withColumn('cleaned response', remove_punctuation_udf(missing_sentiment_dataframe.response)) \\\n",
    "    .withColumn('label', create_labels_udf(missing_sentiment_dataframe.polarity)) \\\n",
    "    .select(F.col('id'), F.col('conversation id'), F.col('turn number'), F.col('speaker'),  F.col('response'), F.col('cleaned response'), F.col('topic'), F.col('polarity'), F.col('label'))\n",
    "    \n",
    "print 'Classifying responses with missing sentiment...'\n",
    "missing_sentiment_prediction_df = en_lr_best_pipeline.transform(cleaned_missing_sentiment_dataframe)\n",
    "#missing_sentiment_prediction_df \\\n",
    "#    .select(F.col('id'), F.col('conversation id'), F.col('turn number'), F.col('speaker'), F.col('response'), F.col('topic'), F.col('polarity'), F.col('prediction')).show(100)\n",
    "positive_predictions = missing_sentiment_prediction_df.filter(missing_sentiment_prediction_df.prediction == 1).select(F.col('response')).collect()\n",
    "negative_predictions = missing_sentiment_prediction_df.filter(missing_sentiment_prediction_df.prediction == 0).select(F.col('response')).collect()\n",
    "\n",
    "positive_predictions = [response.response for response in positive_predictions]\n",
    "negative_predictions = [response.response for response in negative_predictions]\n",
    "\n",
    "print 'Sampling positive and negative predictions...'\n",
    "# Sample positive and negative predictions\n",
    "positive_prediction_sample = random.sample(positive_predictions, 10)\n",
    "negative_prediction_sample = random.sample(negative_predictions, 10)\n",
    "\n",
    "print 'Outputting prediction samples to dataframe...'\n",
    "prediction_sample_dataframe = pd.DataFrame({'Positive Responses': positive_prediction_sample, 'Negative Responses': negative_prediction_sample})\n",
    "z.show(spark.createDataFrame(prediction_sample_dataframe))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%pyspark\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2.0.0 - Scala 2.11",
   "language": "scala",
   "name": "spark2-scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
